WEBVTT

00:05.230 --> 00:06.410
Welcome back everyone.

00:06.460 --> 00:12.490
In this third part of our Arnon with tensor Flo's lecture series we're going to be practicing generating

00:12.490 --> 00:18.040
a new sequence So previously we created a time series sequence that shifted just one time step over.

00:18.040 --> 00:22.060
Now let's go ahead and generate a completely brand new sequence.

00:22.060 --> 00:22.930
So we're going do the following.

00:22.930 --> 00:33.630
We'll say with T.F. session as SPSS we're going to say Savir all restore the model I say.

00:34.110 --> 00:37.530
So session and then go ahead and find it.

00:37.530 --> 00:45.170
So this one I believe is called R and in time series model code along and is going to pass that and

00:45.170 --> 00:51.780
right there and then what I'm going to do is I'm going to first seed it with just a bunch of zeros and

00:51.780 --> 00:52.950
let's see what happens.

00:53.850 --> 00:57.750
So I'll say zero sequence seed.

00:58.020 --> 00:59.480
Let's zoom in on level here.

00:59.490 --> 01:00.730
Scroll down a little bit.

01:00.780 --> 01:07.370
So zero sequence seed that's going to be equal to zero point zero.

01:07.430 --> 01:12.160
For i in range I will say a number of time steps.

01:12.230 --> 01:13.900
So â‚¬30 right there.

01:14.330 --> 01:15.320
And then I'm going to do the following.

01:15.320 --> 01:26.940
I'll say for iteration in the range of the length of TS data X data Minus the number of times that it's

01:29.410 --> 01:39.430
going to perform the following will say X Bachche is equal to an array of zero sequence Seeta and only

01:39.440 --> 01:46.550
go from a negative number of time steps all the way to the end and then going to reshape this to be

01:46.550 --> 01:54.340
in the proper format for r r n n which is going to be one number of time loops one underscore number

01:54.340 --> 02:02.950
of times steps comma 1 and then we need our Y prediction or should I say white generated and that's

02:02.950 --> 02:14.400
going to be to session run and we'll run the outputs where the feed dictionary is just equal to x the

02:14.400 --> 02:16.040
X that we just created there.

02:18.570 --> 02:20.320
And then finally it will say zero.

02:21.960 --> 02:23.000
Sequence seed.

02:23.100 --> 02:29.900
And I'm going to pen those y prediction values 0 negative 1 0.

02:29.920 --> 02:35.740
So I need to index that using pi indexing so I'm in zoom out here.

02:35.950 --> 02:39.720
So again all we're doing is we're going to create this zero sequence scene.

02:39.730 --> 02:44.230
So that's just going to be 30 zeros or however many number of times that we have.

02:44.230 --> 02:49.840
And then for iteration in the range of the length of time series X data Minus the number of times steps

02:50.110 --> 02:52.870
what are going to do is generate an X batch.

02:52.960 --> 02:59.710
So that's going to be passing in the zero sequence array going backwards a negative number of time steps

02:59.710 --> 03:03.800
then go all the way to the end that I you to reshape this for the recurrent neural network.

03:03.830 --> 03:06.300
So anyone come the number of times that's one.

03:06.460 --> 03:07.880
Then I have my prediction.

03:07.890 --> 03:12.350
So I'm just running the outputs passing in that feed dictionary of the next batch I just created up

03:12.350 --> 03:13.000
here.

03:13.120 --> 03:18.150
And then finally I need to append those new values to Mizer a sequence seed.

03:18.340 --> 03:24.950
So at the very end I should have 30 zeros and then the generated values so let's go ahead and run that

03:25.670 --> 03:26.910
and plot it out.

03:27.080 --> 03:34.920
We'll say PBT plot data X data versus zero sequence seed.

03:35.220 --> 03:46.000
And we'll go ahead and have this be a blue line and then also going to plot theist data X data and this

03:46.000 --> 03:48.880
is only going to be for the number of time steps.

03:48.910 --> 04:02.210
So a number of times steps that are going to plot zero sequence seed number of time steps and then finally

04:02.210 --> 04:07.660
will have this be a red line hopes are what make this a little thicker.

04:07.660 --> 04:08.980
Just so we can see it.

04:08.980 --> 04:19.900
So line with is equal to three and it's going to give this an X label of time loops and we'll have wild

04:19.900 --> 04:23.060
label be just white.

04:23.550 --> 04:28.890
So this first one right here that's putting in the entire time series and the second one is going to

04:28.890 --> 04:30.030
be a red line in the case.

04:30.030 --> 04:34.100
The first seed value OK is when we take a look at our results here.

04:34.110 --> 04:39.480
We're definitely providing something that looks sinusoidal but it ends up generating from let's say

04:39.480 --> 04:41.360
negative 0.5 to 1.

04:41.400 --> 04:46.520
So it's not exactly generating a pure sine wave but it's definitely learned that sort of behavior.

04:46.530 --> 04:50.940
So let's go ahead and seat it with something that is the true first sign value.

04:50.940 --> 04:52.860
And let's see how it does with that.

04:52.860 --> 04:55.410
So we'll end up doing is the following.

04:55.680 --> 04:58.510
I'm going to copy this right here.

05:01.340 --> 05:08.270
And paste that and then we'll say time series come along and we're going to see this with the actual

05:08.270 --> 05:08.960
values.

05:09.020 --> 05:16.590
So instead of a zero sequence seat what I'm going to do here is say training instance is going to be

05:16.620 --> 05:21.600
equal to a list of TS data y true values.

05:21.650 --> 05:24.570
And we're just going to take 30 points there.

05:24.710 --> 05:30.620
So then instead of the length of test data the X data minus the number of times steps when I get in

05:30.620 --> 05:37.370
that doing just say the length of the train instance that I just created that X Bache instead of being

05:37.490 --> 05:44.800
zero sequence seed is going to be that training instance instance.

05:44.850 --> 05:45.640
There we go.

05:45.900 --> 05:49.900
And then that needs to have the same dimensions so that reshape is fine as well.

05:50.100 --> 05:52.310
So this line stays the same.

05:52.380 --> 05:58.900
And then instead of appending it to zero sequence c I'm going to append that to the tree instance.

05:58.900 --> 05:59.350
There we go.

05:59.350 --> 06:00.940
So now we're going to run that.

06:01.120 --> 06:06.040
All right so let's plot this out and then scroll back up here and I'm going to copy this and replace

06:06.100 --> 06:07.280
what's necessary.

06:08.420 --> 06:11.290
So instead of saying X data with zero sequence seed.

06:11.300 --> 06:18.340
Now since I actually have a real training instance I could just say TSC data versus Y true.

06:18.480 --> 06:23.910
And then when I got to end up doing is saying the X data X data is fine but replaced this zero sequence

06:23.910 --> 06:27.440
seed with the training instance OK.

06:27.700 --> 06:29.200
That's going to have a saying that mentions.

06:29.230 --> 06:32.010
And let's run this and we can see here.

06:32.050 --> 06:35.340
Now we're predicting pretty much inexact sinusoidal wave.

06:35.410 --> 06:41.020
Now these results won't be perfectly equal to sign of X but they're going to be pretty darn close because

06:41.020 --> 06:43.480
our seed was much better.

06:43.480 --> 06:48.250
Now keep in mind sometimes you'll get weird exponential values especially for the first one.

06:48.250 --> 06:51.470
You may get something that just looks flat and then suddenly explodes.

06:51.580 --> 06:56.920
If that happens to you then usually a good fix for it is just running everything again because sometimes

06:57.910 --> 07:01.720
the graphs session wasn't saved properly and either reset the default graph.

07:01.720 --> 07:06.680
So in that case if you ever get that urge just come over here to colonel and say restart and run all

07:07.060 --> 07:08.680
and make sure you use the provided notebook.

07:08.680 --> 07:14.350
It's really easy to get a typo in here or mess up a line or just mix up the graphs.

07:14.350 --> 07:19.630
So again always use the provided notebook because there's lots of ways to just make small typos and

07:19.660 --> 07:20.790
mess this up.

07:20.860 --> 07:23.310
All right so I hope you enjoyed this lecture series.

07:23.320 --> 07:27.100
I think this last part is really one of the most interesting aspects of our current neural networks

07:27.370 --> 07:31.920
the ability to just completely generate new sequences based off what it's seen before.

07:32.140 --> 07:36.050
And what's really cool is the pinning on the seat value you make it something unique and different.

07:36.130 --> 07:41.230
So you can imagine that if we were trying to generate something like music or we had words we could

07:41.230 --> 07:45.920
give it certain seeds and it would generate a unique instance that we've actually never seen before.

07:45.940 --> 07:50.530
So this is the cool way you could use recurrent neural that works to maybe journey new pieces of music

07:50.530 --> 07:52.220
or something similar to that.

07:52.600 --> 07:53.140
All right.

07:53.140 --> 07:53.950
Hope you enjoyed that.

07:53.950 --> 07:59.180
Coming up next it's going to be an exercise that allows you to walk through this for a time series.

07:59.230 --> 07:59.700
Thanks.

07:59.710 --> 08:00.820
And I'll see you at the next lecture.
