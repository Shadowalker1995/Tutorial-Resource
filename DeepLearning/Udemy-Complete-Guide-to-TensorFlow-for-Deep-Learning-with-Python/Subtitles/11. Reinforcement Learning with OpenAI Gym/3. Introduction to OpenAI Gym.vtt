WEBVTT

00:05.420 --> 00:07.150
Hello everyone and welcome to this lecture.

00:07.150 --> 00:08.990
We're going to be discussing open aiight.

00:08.990 --> 00:11.570
Jim what is the toolkit open.

00:11.570 --> 00:16.280
AI is the basic nonprofit organization that's behind this tool kit.

00:16.400 --> 00:19.810
And then we'll also discover the documentation behind open eyes.

00:19.820 --> 00:26.660
So first off let's discuss what is open A-I open and it is a nonprofit AI research company.

00:26.690 --> 00:32.330
You may have heard of opening before due to its ties with people like Elon Musk or Sam Altman and their

00:32.330 --> 00:38.750
basic motivation is to help discover and enact a path to safe artificial general intelligence.

00:38.780 --> 00:44.510
If you follow the mosque and his comments on the dangers of artificial intelligence you may already

00:44.510 --> 00:52.010
have some familiarity of this but basically open he is trying to bring a path forward where the basic

00:52.010 --> 00:58.670
research of artificial intelligence is more shared more collaborative more open in hopes of enacting

00:58.670 --> 01:03.490
a safe path for the general development of artificial intelligence.

01:03.500 --> 01:07.710
So what ends up happening is that they released this toolkit called Jim.

01:07.940 --> 01:11.410
So that's what we're actually going to be working with open aiight Jim.

01:11.600 --> 01:17.370
And that's a tool kit the AIDS in developing and comparing reinforcement learning algorithms.

01:17.400 --> 01:23.220
There's two parts to open AI Jim and the part we're really going to be dealing with is the open AGM

01:23.310 --> 01:25.710
library and the Python library.

01:25.740 --> 01:30.250
That means we're actually going to directly import it will say import Jim and you can use pipin knowledge

01:30.250 --> 01:31.220
him to install it.

01:31.500 --> 01:36.270
But it's a python library with a collection of environments that you can use with your reinforcement

01:36.270 --> 01:37.560
learning algorithms.

01:37.680 --> 01:43.950
And basically before opening I Jim it was quite difficult to try to get some sort of general environment

01:43.950 --> 01:46.220
for your reinforcement learning algorithms.

01:46.290 --> 01:52.740
But now with opening gym it becomes a lot easier to test reinforcement algorithms on the same environment

01:52.800 --> 01:54.700
as someone else on a computer.

01:54.780 --> 01:56.340
Maybe half the world away.

01:56.430 --> 02:01.230
So it makes it really convenient to build models and compare models.

02:01.230 --> 02:03.650
So we'll be using the Python library.

02:03.660 --> 02:07.170
There is another aspect of open the gym that I want to talk about.

02:07.230 --> 02:13.290
We won't really be using it but it's the open gym service and it's a site in API we can compare algorithm

02:13.290 --> 02:19.320
performance on the environments the opening gym provides So what we're going to do is we're going to

02:19.320 --> 02:22.200
explore the official documentation before diving into work.

02:22.240 --> 02:24.080
Opening gym with Python.

02:24.120 --> 02:28.950
Just seeing it a little bit more familiar with what the actual documentation pages look like.

02:28.980 --> 02:30.830
So open up your browser and go to gym.

02:30.870 --> 02:34.960
Open AAE dot com or just do a quick Google search for open gym.

02:34.980 --> 02:37.240
And so probably the first page that pops up.

02:37.260 --> 02:39.450
So let's open up our browser and head to that.

02:39.570 --> 02:39.810
OK.

02:39.810 --> 02:41.450
Here I am in my browser.

02:41.610 --> 02:47.870
If you go to gym opening dot com it should automatically link you back to the page.

02:47.910 --> 02:51.510
So here you can see the open aiight gym is totally open source.

02:51.510 --> 02:56.220
You can check out all the code all the examples et cetera as well as the documentation page.

02:56.370 --> 03:00.600
But in case you're having trouble finding this one I want to do show you how you can get this just from

03:00.600 --> 03:02.950
going from opening his official Web site.

03:03.180 --> 03:04.920
So let's hop over to that here am.

03:04.960 --> 03:06.450
Opening night dot com.

03:06.630 --> 03:11.340
A lot of times it changes what the actual home page looks like but you should see some sort of link

03:11.340 --> 03:16.340
to their systems either down here or over the top navigation bar.

03:16.410 --> 03:20.330
So you click on systems and eventually somewhere along this page you should see.

03:20.360 --> 03:22.690
Jim says Jim the open air that.

03:22.860 --> 03:24.090
You'll go ahead and click on that.

03:24.150 --> 03:29.300
It'll take you to Jim the opening column which currently links to this page.

03:29.310 --> 03:35.180
So if you scroll down on this page eventually you should see that it has some link for the documentation.

03:35.400 --> 03:40.590
So you click on that and it will take you to the more documentation like page and then you can hit here

03:40.590 --> 03:42.440
on view documentation.

03:42.450 --> 03:45.350
And here is the official documentation for opening night Jim.

03:45.360 --> 03:47.460
So this is what we're going to be learning about.

03:47.730 --> 03:51.850
And as I just mentioned it consists of two parts the open source library which is mainly what we're

03:51.900 --> 03:55.100
going to be dealing with and this is basically a collection of environments.

03:55.100 --> 04:00.360
So that's the really hard part that Jim has basically taken care of for you if it's providing you with

04:00.360 --> 04:07.500
environments that you can have your agent interact with take actions upon etc. to try to find some sort

04:07.500 --> 04:08.570
of reward.

04:08.580 --> 04:13.610
So if you click here on environments you can check out the various environments are.

04:13.650 --> 04:17.610
So there's a bunch of the free environments right now and depending on when you're viewing this page

04:17.610 --> 04:19.410
sometimes those pictures don't load.

04:19.410 --> 04:22.920
But there is a cart pulling environment which that's the main thing we're actually going to be messing

04:22.920 --> 04:23.710
around with.

04:23.760 --> 04:26.520
But there's also a boardgame environment such as go.

04:26.700 --> 04:30.060
So if you ever heard of Google's deep mind you're probably familiar go there.

04:30.060 --> 04:34.970
And then there's also Atari games such as aere Pac-Man alien cetera.

04:35.010 --> 04:41.190
Keep in mind some of these environments such as Atari require additional libraries to install such as

04:41.190 --> 04:42.690
an Atari emulator.

04:42.690 --> 04:47.520
So we're only going to be dealing with these classic control problems that don't require any additional

04:47.520 --> 04:48.420
libraries.

04:48.420 --> 04:53.740
If you do require other environments go ahead and read the official documentation and additional libraries

04:53.740 --> 04:55.540
you need to install for this course.

04:55.560 --> 04:59.820
We're going to try to keep things as simple as possible for our reinforcement learning lecturers so

04:59.820 --> 05:04.460
we'll only deal with things that don't require an additional library beyond Jim.

05:04.560 --> 05:07.860
So we have a Tory board games Toltecs safety.

05:07.860 --> 05:14.460
There's even Minecraft there's soccer there's doom etc. So lots of stuff here on these environments

05:14.640 --> 05:16.810
and you can check the documentation as well.

05:16.860 --> 05:20.660
And there's also even a forum they can click around and play around with.

05:20.980 --> 05:21.570
OK.

05:21.780 --> 05:23.290
So that's all I wanted to show you.

05:23.340 --> 05:28.290
As far as opening night Jim is concerned we're going to do in the next series of lectures is actually

05:28.290 --> 05:34.430
show you how upon installing opening a gym how you can interact with it as a Python library.

05:34.440 --> 05:36.300
Thanks everyone and I'll see you at the next lecture.
