WEBVTT

00:06.080 --> 00:10.160
Hello everyone and welcome to part two of the convolutional neural networks.

00:10.460 --> 00:12.410
We're going to continue right where we left off.

00:12.410 --> 00:17.630
Remember we were discussing the original convolutional neural network diagram and we were trying to

00:17.660 --> 00:20.630
get a understanding of what the convolutions were.

00:20.660 --> 00:26.540
Now what we need to do is discuss the subsampling or pooling portion of a convolutional neural network

00:26.690 --> 00:28.490
and it's actually quite a simple idea.

00:30.460 --> 00:37.480
So pooling layers will subsample the input image which reduces the memory use in computer load as well

00:37.480 --> 00:40.330
as reducing the number of parameters.

00:40.340 --> 00:43.530
Let's imagine we have a layer of pixels in our image.

00:43.550 --> 00:47.960
Here we have a relatively simple input image is just six by six.

00:48.020 --> 00:53.120
And recall that for this digital data set each pixel has some sort of value representing what we will

00:53.120 --> 00:57.460
call a darkness so 0 to 1 or maybe negative 1 2 1 etc..

00:58.210 --> 00:59.820
So here we have numbers filled out.

00:59.920 --> 01:04.870
You can imagine that this grid is entirely filled with numbers and the way pooling works is we create

01:04.930 --> 01:08.280
a two by two pool of pixels and that's known as a kernel.

01:08.530 --> 01:12.340
And then we evaluate the maximum value and it doesn't have to be two by two.

01:12.340 --> 01:15.760
It can be in any size you want but two by two is a pretty common choice.

01:15.760 --> 01:22.250
Again kind of depends on the size of your input data and what you do is inside of two by two kernel.

01:22.270 --> 01:27.910
You evaluate the maximum value and only the max value makes its the next layer.

01:27.910 --> 01:33.830
So you basically decide the maximum value is going to be representative of the entire kernel.

01:34.090 --> 01:39.280
So here we can see we have a two beta kernel we check OK what is the maximum pixel value and that's

01:39.280 --> 01:41.850
the only value that makes it the next layer.

01:41.890 --> 01:43.540
Then we move over by a stride.

01:43.540 --> 01:49.690
In this case we can imagine our stride is to grab the max value there and continue along.

01:49.720 --> 01:54.400
Now this pooling layer is going to end up removing a lot of information and even a small pulling kernel

01:54.400 --> 01:59.870
of two by two with a stride of two actually ends up removing 75 percent of the input data.

02:00.130 --> 02:05.980
However we should know that this is a really common step of convolutional neural networks as that vast

02:05.980 --> 02:07.780
amount of input data from an image.

02:07.870 --> 02:15.900
It's just basically going to be too computationally expensive to not have pooling layers for now another

02:15.900 --> 02:19.770
common technique deployed of convolutional neural networks is called dropout.

02:19.830 --> 02:23.140
Now we've actually discussed dropout in the past but let's have a quick review.

02:23.400 --> 02:28.650
Dropout can essentially be thought as a form of regularization to help prevent overfitting and during

02:28.650 --> 02:29.240
training.

02:29.310 --> 02:36.070
Units are randomly dropped along with their connections and this helps prevent units from CO adapting

02:36.070 --> 02:39.400
too much to any particular training set.

02:39.430 --> 02:44.100
Now it's also quickly point out some famous convolutional neural network architectures.

02:44.180 --> 02:50.760
So we already discussed Linette Phi and Lakhan But there's also famous sets like Alex that Google that

02:50.850 --> 02:56.810
are Googling that read that and you can check out the research links to papers discussing these architectures.

02:56.810 --> 03:03.810
But essentially each of these architects architectures is just a set of design of layers.

03:04.280 --> 03:09.800
So for example in Alex that will look like this it has a particular stride for its convolution that

03:09.800 --> 03:15.380
has a particular pooling layer that another pulling layer than another convolution etc. and we can see

03:15.380 --> 03:20.450
here Alex that basically the first convolutions or just edges and blobs.

03:20.450 --> 03:26.210
Then the third convolution suits Cripe texture convolutions as we go higher and higher we get higher

03:26.210 --> 03:32.480
abstraction so then we can see the object parts and then we can eventually see objects classes able

03:32.480 --> 03:38.150
to distinguish things between like a dining table or clock a ship etc. so you can see here it's able

03:38.150 --> 03:42.770
to do up to a thousand or a hundred classes.

03:42.780 --> 03:49.080
Now realistically Alex that is so computationally expensive that it's actually distributed apart multiple

03:49.080 --> 03:49.810
GPS use.

03:49.890 --> 03:55.890
So you end up seeing diagrams that look like this where only half the image is going into one GPU and

03:55.890 --> 03:59.600
the other half is going to another chip you.

03:59.800 --> 04:03.230
OK so now he should fully understand the convolutional neural network.

04:03.250 --> 04:08.290
Remember we have convolutions then we have subsampling or pooling and eventually towards the end we

04:08.290 --> 04:13.990
have some sort of densely connected neural network and we can even have a soft Max regression if you

04:13.990 --> 04:17.460
want to use that for our output.

04:17.480 --> 04:21.770
You can check out the various supplementary resources that are linked to at the very beginning of the

04:21.770 --> 04:22.710
section of the course.

04:22.730 --> 04:27.020
But now that we've covered the basics of convolutional neural networks let's go ahead and explore how

04:27.020 --> 04:30.680
to implement one intenser flow on the data set.

04:30.690 --> 04:31.670
I'll see you at the next lecture.
