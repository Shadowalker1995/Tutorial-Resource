WEBVTT

00:05.310 --> 00:10.770
Welcome back everyone to part four of our Q and A bot with Python 4 Part 4.

00:10.770 --> 00:15.030
We're going to fit and train the network or at least show you how to fit and train the network.

00:15.030 --> 00:16.980
It takes quite a long time to train this network.

00:17.220 --> 00:21.150
So we're going to show you how to train it but then we'll cancel the training and then just show you

00:21.150 --> 00:25.620
how to load the pre train model that we provide for you optionally it's up to you if you want to train

00:25.620 --> 00:28.250
your own model on more epochs and what we did.

00:28.350 --> 00:33.210
We have a model that was trained on one hundred epochs took a bit of time and we have that for you as

00:33.210 --> 00:37.830
an H5 file they can easily load up so we'll show how to train the network will kind of cancel the training

00:37.860 --> 00:42.390
then load up the pre train network if you want you can wait for the training and then we will plot out

00:42.390 --> 00:47.250
the training history and then evaluate on our own test set and then what's really cool is we'll be able

00:47.250 --> 00:52.470
to create our own stories and our own questions and then see if our network is able to answer some simple

00:52.470 --> 00:53.310
questions.

00:53.370 --> 00:57.630
Let's get started by jumping back to the notebook OK.

00:57.640 --> 01:03.110
Recall last time we finished up our model by compiling it and then we have our summary of our model.

01:03.130 --> 01:06.150
Now it's time to fit the model to do this.

01:06.220 --> 01:13.890
We're going to assign a history variable and then we'll say model dot fit and then as a list will pass

01:13.890 --> 01:22.170
in inputs train that we created earlier and then we will say queries train source and see training on

01:22.170 --> 01:27.960
the input stories as well as the input questions the training set ones at least.

01:27.960 --> 01:37.730
And then finally those were our exes and then we'll say answers train is the correct label you pass

01:37.740 --> 01:40.910
in a batch size so let's use a batch size of 32.

01:40.960 --> 01:46.300
This is something you can experiment with smaller batch sizes with longer training epochs should lead

01:46.630 --> 01:47.790
to slightly better results.

01:47.800 --> 01:52.370
But the one we train for was epochs one hundred.

01:52.400 --> 01:55.840
So we train four hundred epochs in the model that we provide for you.

01:55.880 --> 01:57.230
Doesn't take that long to train.

01:57.230 --> 02:02.330
It's about five to 10 seconds per step on a pretty fast graphics card.

02:02.330 --> 02:07.640
But if you're just running this on you it could be a quite a more maybe 30 to 60 seconds per step so

02:07.640 --> 02:11.840
you can imagine for 100 epochs you're looking at six thousand seconds so that's quite a bit of time

02:13.090 --> 02:17.420
we'll go ahead and just show you what this looks like what we'll train for just three epochs.

02:17.420 --> 02:22.340
But again we provide a model for you in fact if you go to the departing folder there is a file called

02:22.420 --> 02:24.490
Chapel underscore 10 that H5.

02:24.620 --> 02:28.670
This is the one hundred epoch model that will load up in just a little bit.

02:28.720 --> 02:33.020
The first illustrate how to train your own model in case you want to train it then we'll say validation

02:33.170 --> 02:35.540
underscored data is equal to.

02:35.570 --> 02:43.440
And here we're going to pass in a tuple with the same format as training data which is input test queries

02:43.440 --> 02:49.230
test and then into this tuple will say answers test.

02:49.230 --> 02:53.220
So let me zoom out here just so you can make sure you get the entire format.

02:53.300 --> 03:00.320
Notice my validation data itself is a tuple here where the first item in the tuple is a list of two

03:00.320 --> 03:02.560
elements the inputs test and the queries test.

03:02.660 --> 03:04.910
And the second item is just answers test.

03:04.910 --> 03:06.980
So go ahead and run this.

03:06.980 --> 03:12.470
Make sure we don't commit any typos and then you should see training on 10000 samples validate on a

03:12.470 --> 03:13.670
thousand samples.

03:13.670 --> 03:17.600
Again this may take a while depending on how fast your computer is.

03:17.600 --> 03:21.410
So right now I'm looking at about eight seconds but I have a really fast GPO.

03:21.800 --> 03:27.350
So if you have a slower CPA or GP you depending on what you're running this on it could take quite a

03:27.350 --> 03:32.390
bit of time and notice accuracy still isn't that good 50 percent which is essentially it's random guessing

03:32.420 --> 03:33.590
yes or no.

03:33.590 --> 03:37.760
And what we're gonna do now is show you how you could evaluate and plot out the training history of

03:37.760 --> 03:41.180
your model and then we'll show you had actually load up the model that we created.

03:42.080 --> 03:48.230
So if you wanted to plot out your training history I'm going to copy and paste the code that we provided

03:48.230 --> 03:51.440
for you inside of our provided notebook.

03:51.500 --> 03:57.920
So as a quick note if you open up our provided notebook right after this training step there's a saving

03:57.920 --> 03:58.920
the model step.

03:59.090 --> 04:02.780
I would not recommend overwriting the model that we created for you.

04:02.780 --> 04:05.160
And then there's a plotting out training history.

04:05.210 --> 04:09.680
This is essentially just a bunch of map plot lib code which gives you a nice little plot like this.

04:09.680 --> 04:14.420
It's actually pretty straightforward we just plot out the history of the accuracy for the training set

04:14.540 --> 04:17.250
as well as our validation accuracy for the test set.

04:17.270 --> 04:21.730
So I'm just going to copy and paste this code.

04:21.780 --> 04:25.000
So it's essentially just a bunch of title calls and plot calls.

04:25.000 --> 04:27.320
So going to copy that.

04:27.400 --> 04:33.110
So again copying it and then pasting it right here and let's go ahead and run that.

04:33.130 --> 04:38.560
Remember we only trained for three epochs so it's gonna be kind of not a very impressive chart.

04:38.770 --> 04:44.560
So this is on the first epoch or essentially where it started the first epoch and then the second epoch.

04:44.560 --> 04:49.360
So not a whole lot of information here but as you train for more and more epochs for example I'll go

04:49.360 --> 04:56.320
ahead and retrain for a ten epochs and then plot this out again while we wait for these tiny epochs

04:56.320 --> 05:01.750
let me explain what's going on here in this plotting line we're importing my public SPL BLT we saying

05:01.780 --> 05:06.790
map published lib in line in order to see the chart in line in this notebook the most recent version

05:06.790 --> 05:10.600
of Jupiter no longer requires this but just the case you're using an older version I put it in there

05:11.110 --> 05:16.390
and then I printed out the history that history donkey's history the history keys there's essentially

05:16.870 --> 05:22.270
four items returned back and it's your validation loss validation accuracy and then your training loss

05:22.330 --> 05:27.580
and trainee accuracy so sometimes you'll see people plot out the loss sometimes you'll see people plot

05:27.580 --> 05:32.650
out the accuracy they're essentially in versus of each other right you're trying to either increase

05:32.650 --> 05:37.880
your accuracy or reduce your loss depending on how you're thinking about the training.

05:37.960 --> 05:45.150
So here we can see kind of a more realistic beginning of the curve that are more epochs or certainly

05:45.160 --> 05:46.630
get better accuracy.

05:46.630 --> 05:51.930
So after ten epochs we can see our accuracy is slowly improving again it makes sense that our default

05:51.940 --> 05:57.280
accuracy starts off at 50 percent because the correct answers are either only yes or no.

05:57.280 --> 06:02.020
So even in totally untrained neural network you get about 50 percent accuracy if you just randomly guessing

06:02.050 --> 06:07.900
yes or no depending on some random initialization of those weights you'll be correct about 50 percent

06:07.900 --> 06:13.030
of the time and then off of this we're just plotting history accuracy history validation accuracy for

06:13.030 --> 06:18.310
those keys and if you wanted to you don't have to plot train and test but it should apply to kind of

06:18.310 --> 06:23.870
see the point at where you're no longer getting any improvement on your test data.

06:23.870 --> 06:28.810
And for my particular program that happened around 40 epochs so maybe training for a hundred epochs

06:29.110 --> 06:34.660
isn't even that useful since you should get results that are pretty darn good around maybe 80 percent

06:34.660 --> 06:37.680
accuracy area test set around the 50 epoch Mark.

06:37.750 --> 06:37.990
All right.

06:38.470 --> 06:45.760
So if you wanted to save this model all you need to do is say model that save and choose some sort of

06:45.760 --> 06:46.300
file path.

06:46.300 --> 06:50.830
So my brand new model dot H5.

06:50.920 --> 06:56.540
So that would say this H5 waits under whatever you just trained up here.

06:56.620 --> 07:01.080
Now in our case we're going to use the model that we've already trained for you.

07:01.240 --> 07:02.560
And again that is the chapel.

07:02.590 --> 07:04.160
Underscore ten dot H five.

07:04.240 --> 07:16.520
So I'm going to load up that model so I will say model that load weights and against called Chaput underscore

07:16.570 --> 07:17.330
that H5.

07:17.520 --> 07:23.230
You have to be in the correct notebook if you want you could just pass an entire file path to this H5

07:23.230 --> 07:23.590
folder.

07:23.620 --> 07:27.790
But I recommend running this inside the deep learning folder so you don't get any errors.

07:27.790 --> 07:29.260
So go ahead and load those weights.

07:29.260 --> 07:33.730
Now you have our hundred epoch trained model and then we're going to use this to evaluate on the given

07:33.730 --> 07:34.780
test set.

07:34.780 --> 07:40.790
So we want to do is want to predict results for the input test and the queries test so we'll say predicted.

07:40.810 --> 07:43.810
Let me zoom in here so we can see the code a little better.

07:43.810 --> 07:52.240
We'll say predicted results or pred results is equal to model that predict and as a tuple that has two

07:52.240 --> 07:57.940
inputs the first input is inputs test and then the second item.

07:57.940 --> 08:01.570
It's actually in this list is queries underscore a test.

08:01.570 --> 08:09.190
So here I have a tuple of a single item where the single item is a list of two items inputs test and

08:09.190 --> 08:10.270
queries test.

08:10.270 --> 08:16.210
It makes sense that I no longer pass in answers because I'm trying to predict based off my test set.

08:16.210 --> 08:20.890
I don't want to pass on answers nor do I have a need to because I'm not predicting answers based off

08:20.890 --> 08:21.430
the test set.

08:21.850 --> 08:26.950
So again if you want to predict based off new stories new questions you simply call the predict method

08:26.950 --> 08:32.640
off your model and then using this formatting you pass in a new story and a new set of questions and

08:32.640 --> 08:36.190
we'll show you how to write your own stories on questions in just a little bit.

08:36.460 --> 08:37.580
So go ahead and run that.

08:37.690 --> 08:40.480
It should predict some results for you.

08:40.540 --> 08:41.950
Remember our test data.

08:42.100 --> 08:45.310
If we take a look at it it's essentially I run this whole thing.

08:45.400 --> 08:47.820
It's tuples right where we have the story.

08:48.040 --> 08:53.980
The question and then the answer so I can take a look at the first story here and says Mary got the

08:53.980 --> 08:55.140
milk there.

08:55.300 --> 08:58.590
John moved to the bedroom and is going to ask something like where's John.

08:58.930 --> 09:03.510
So we're going to do now is generate the prediction from the actual model.

09:03.520 --> 09:08.320
So if I take a look at the pred results is essentially just a bunch of probabilities.

09:08.320 --> 09:12.400
Notice that it actually has probabilities for every single word.

09:12.460 --> 09:16.790
So I check the shape of this it's 1000 by 38.

09:16.810 --> 09:23.110
So we have thirty seven vocab words plus one extra for padding and then we had 1000 Test stories test

09:23.110 --> 09:24.750
questions and test answers.

09:24.790 --> 09:32.110
So if I take a look at the very first one here ups make sure we grab zero off predict the results.

09:32.130 --> 09:35.380
These are the probabilities for every single vocab words.

09:35.460 --> 09:41.130
It makes sense that the probabilities for random words like John and moved based off the token a or

09:41.130 --> 09:45.960
word index should be extremely low because we wouldn't expect the correct answer to be something like

09:46.050 --> 09:51.450
milk to a question of is John in the kitchen which is the question that goes along with this first test

09:51.450 --> 09:52.490
dataset.

09:52.500 --> 09:58.380
So we're gonna do is we're then going to perform ARG Max in order to figure out which of these words

09:58.380 --> 10:01.020
has the max probability and it should be either yes or no.

10:01.650 --> 10:07.910
So the way we can generate a prediction directly of yes or no we're just going to say my max value essentially

10:07.950 --> 10:14.600
the max probability is equal to FP ARG Max of predicted results.

10:14.630 --> 10:19.750
Let's go ahead and just do the first one so I'm actually gonna print out everything for the first test

10:19.750 --> 10:20.050
data.

10:20.620 --> 10:21.580
So say test data.

10:21.580 --> 10:22.650
Mary got the milk there.

10:22.660 --> 10:24.900
John moved to the bedroom.

10:24.960 --> 10:30.850
The question was Is John in the kitchen and then the correct answer was No.

10:30.850 --> 10:31.400
He is not.

10:31.400 --> 10:32.290
He moves to the bedroom.

10:32.310 --> 10:33.110
Right.

10:33.170 --> 10:39.050
So let's go ahead and see what the prediction was based off this first prediction results.

10:39.050 --> 10:41.220
So I have my VAX maximum value.

10:41.360 --> 10:51.510
And then what I can do here is simply say for key val and took a nicer word index items.

10:51.640 --> 10:59.260
No word index items essentially just the the word index and the word itself will say if vow is equal

10:59.260 --> 11:05.510
to Val Max K's equal the key essentially just searching for the word.

11:05.630 --> 11:09.870
And then once you run that if you go ahead and just print out k it should tell you know as long as you

11:09.870 --> 11:13.690
trained it enough epochs because it's asking us is John in the kitchen.

11:13.730 --> 11:14.560
It's no.

11:14.570 --> 11:22.010
We can also check how sure it is of this by simply grabbing the predicted results at that in the exposition

11:22.100 --> 11:28.970
of zero and then calling Val underscore Max is essentially going to return back to direct probability

11:28.970 --> 11:31.330
that we saw up here.

11:31.640 --> 11:36.530
So we're gonna run this and now we can see the model is ninety nine point nine percent sure that John

11:36.590 --> 11:38.300
isn't in the kitchen.

11:38.300 --> 11:38.650
All right.

11:39.020 --> 11:43.340
So now comes the really cool part where we're going to write our own stories and questions and then

11:43.430 --> 11:45.350
run them through the actual model

11:48.100 --> 11:53.050
something you're going to need to be aware of as you're doing this is recall we have a set vocabulary

11:54.490 --> 11:59.090
so if I say vocab these are the only words that my model is aware of.

11:59.170 --> 12:03.580
Which means these are the only words I can use for testing the model.

12:03.580 --> 12:07.630
I can't write in proper names or other verbs that it won't understand.

12:07.660 --> 12:10.370
So keep that in mind as you're writing your own stories.

12:10.420 --> 12:15.310
You're going to have to not only format it in the correct way but be limited to the vocabulary that

12:15.310 --> 12:16.720
our network was trained on.

12:16.780 --> 12:21.340
You can't do things like was hose a in the Super Bowl or something like that because it doesn't know

12:21.340 --> 12:24.690
what Hosey is this note the Super Bowl is et cetera.

12:24.700 --> 12:27.250
So let's go ahead and create a story first.

12:27.340 --> 12:34.530
So I will say the following I will say my story and I was going to type this out as a string and something

12:34.540 --> 12:40.090
we're also going to have to do is keep a space in between punctuation as I'm not sure what I mean by

12:40.090 --> 12:40.750
that.

12:40.840 --> 12:47.110
We're going to say Jon left the kitchen space period.

12:47.260 --> 12:53.630
Space Sandra dropped and then you can look for any object here.

12:53.640 --> 12:54.710
I see we have football.

12:54.720 --> 12:58.150
So we'll go ahead and drop the football and we'll drop it in the garden.

12:58.710 --> 13:07.800
So say Sandra dropped the football in the garden space period.

13:07.980 --> 13:13.410
And the reason we have these spaces after the period is because right after this.

13:13.410 --> 13:16.980
I want to make sure my story is in the same format as what it was trained on.

13:17.120 --> 13:22.380
And recall our test data is a list here where the punctuation is separated.

13:22.380 --> 13:28.560
So all I need to do is say the following we will say my story and then we just need to split it.

13:29.250 --> 13:31.380
So let's go ahead and do that.

13:31.470 --> 13:37.400
We will say my underscore story and then call that split.

13:37.640 --> 13:42.860
And here we can see my story is now basically in the same sort of formatting that the test data was

13:42.860 --> 13:52.670
in or the training data then we'll create one more for my question and we'll say my underscore question

13:53.360 --> 14:02.730
is equal to and let's ask about that football will say is the football in the garden space question

14:02.730 --> 14:07.380
mark and recall that the question should also be split for the formatting.

14:07.380 --> 14:13.290
So if we come back here and look at our original training data remember these questions for the test

14:13.290 --> 14:16.310
data and the training data are also a list of all the words.

14:16.440 --> 14:17.870
So we'll do the same thing here.

14:17.960 --> 14:24.110
We'll say my question that split and we'll see that this is the format we need the question is.

14:24.280 --> 14:27.450
So let's create a brand new dataset of just one single story.

14:27.490 --> 14:32.880
One single question and then also a single answer and we'll pass it into our vector rise data function.

14:33.010 --> 14:38.500
So we'll say my data is equal to and this is exactly what you would need to do if you wanted to expand

14:38.500 --> 14:40.400
your training set or your test set.

14:40.450 --> 14:46.240
You could hire somebody or you yourself could create new stories new questions and then correct answers.

14:46.240 --> 14:51.610
So the way it's going to work is we're simply going to make a list because remember our training data

14:51.610 --> 14:54.230
was just a list of three item tuples.

14:54.400 --> 15:02.830
So here is just going to be one tuple where it's my story that split it's my question thought split

15:03.870 --> 15:07.220
and then the correct answer in this case is the football in the garden.

15:07.230 --> 15:11.070
Well it is because Sandra dropped the football in the garden so we'll say the answer is yes.

15:12.090 --> 15:18.210
OK so now we have a data set which is in the exact same format of my original training data and my original

15:18.210 --> 15:23.610
test data except this time is just one single set of question or story question and answer.

15:23.610 --> 15:27.060
It's not a bunch of them as the training data was or the test data was.

15:27.270 --> 15:32.840
So I have my data in the exact same format as expected by the victories story function.

15:32.840 --> 15:33.230
No.

15:33.690 --> 15:36.060
We create a function earlier that vector I stories.

15:36.150 --> 15:43.340
So all I'm going to do is pass in my data here and I'm going to impact this to be my story my quests

15:44.180 --> 15:51.710
and my aunts for my answer run that and I have a vector res version of my story so if you check out

15:51.710 --> 15:55.710
my story here it's now been victimized with some padding here.

15:55.880 --> 16:02.370
It's the same thing for my question and the same thing for my answer.

16:02.390 --> 16:03.930
So this is all ready to go.

16:03.950 --> 16:09.700
Now what I want to do is call the model and predict only off my story and my question.

16:09.740 --> 16:13.310
So just as before we're just going to copy and paste what we did earlier.

16:13.310 --> 16:18.470
So you can always predict on a new set of data just as you predicted on the test set will come back

16:18.470 --> 16:22.950
here and call pred results is modeled up predict.

16:23.030 --> 16:28.040
So I'm going to copy this and in machine learning again the way you predict on your data is the same

16:28.040 --> 16:29.870
we predicted on the test data.

16:29.870 --> 16:35.300
So here we are calling to call a model that predict except this time instead of inputs test and queries

16:35.300 --> 16:36.500
test all Pessin

16:39.680 --> 16:47.970
my story and my question and now I have the predicted results just for that single story and just for

16:47.970 --> 16:55.290
that single question let's go ahead and copy and paste what we also said here which was just that Max

16:55.410 --> 16:57.600
is NPR predicted results.

16:59.590 --> 17:04.210
Remember predictive results has not been changed to only my story my question and right now we're just

17:04.210 --> 17:11.420
looking to predict the results of the first item will come back down here and run this.

17:11.830 --> 17:13.290
Check out what case.

17:13.420 --> 17:15.130
And we say K is yes.

17:15.160 --> 17:20.490
So we have a model that predicted correctly amazingly on our own story on our own question.

17:20.500 --> 17:23.940
I hope you realize just how basically freaking awesome this is.

17:24.010 --> 17:29.080
You can write your own stories your own questions within the limitations the vocabulary and the model

17:29.320 --> 17:35.170
with pretty good accuracy is going to respond correctly to a lot of these questions that you create

17:35.290 --> 17:36.340
for yourself.

17:36.400 --> 17:41.090
So if you want to figure out how sure it was you simply need to say predict the results.

17:41.140 --> 17:50.460
0 at the maximum value and what's predicted results plural and you can see that it was around ninety

17:50.460 --> 17:56.030
nine point two percent sure that it was the correct answer yes.

17:56.160 --> 18:01.320
All right I hope you enjoyed this exercise for creating our own chat bots and I would love to see how

18:01.320 --> 18:06.210
you can expand this to your own stories and your own datasets for your own problems either for your

18:06.210 --> 18:07.910
own projects or work.

18:07.980 --> 18:09.420
Thanks and we'll see you there.
