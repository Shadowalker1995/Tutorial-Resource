WEBVTT

00:05.450 --> 00:10.290
Welcome back everyone to part three of our Cuban report with python as a quick note.

00:10.290 --> 00:13.470
Make sure to read the paper before continuing onto this lecture.

00:13.470 --> 00:17.430
If you still haven't read the paper that we're working off of it's really important that this point

00:17.430 --> 00:22.110
in time you read it since going to be fundamental to understanding how the network and the encoders

00:22.110 --> 00:28.440
work so in this lecture we're going to be building out the neural network including input encoder M

00:28.860 --> 00:33.000
input encoder C the question encoder and then we'll complete the network.

00:33.150 --> 00:35.440
Let's jump to the notebook and get started.

00:35.460 --> 00:40.230
All right here we are at the notebook we left off last time and again just to reiterate by now you should

00:40.230 --> 00:43.530
have read the paper to understand the encoders in the full network.

00:43.560 --> 00:48.900
So here's the paper Here's essentially the diagram of the network that we're producing along the encoders

00:48.960 --> 00:53.760
and the long short term memory unit or the recurrent neural network that sees from the paper.

00:53.760 --> 00:58.800
So we're gonna be working on the encoders for the questions and the stories those encoders see an M

00:58.800 --> 00:59.580
from here.

00:59.730 --> 01:01.530
And we're gonna be building this out with Python.

01:01.560 --> 01:03.900
So make sure you read this paper before continuing on.

01:03.900 --> 01:06.250
Otherwise I don't really make sense what we're doing.

01:06.240 --> 01:11.030
It's really come back here and start off with a lot of imports in order to build out these networks

01:11.040 --> 01:20.220
we'll say from Kerry's models import sequential and model and then from Carrier start layers that embedding

01:20.220 --> 01:33.890
is import embedding and then from Carrier stock layers we're going to import input activation dense

01:35.230 --> 01:47.280
per mute and drop out and then we'll also import the operations add dots and concatenate and we actually

01:47.380 --> 01:52.030
import one more thing from layers which is the Ellis team the long short term memory unit that we're

01:52.030 --> 01:58.800
gonna be using OK so we have our sequential and model imported from carrier not models we have our embedding

01:58.800 --> 02:04.100
is imported specifically from layers that embedding so that we can just call embedding and then we have

02:04.250 --> 02:06.600
all these various imports from carriers that layers.

02:06.680 --> 02:10.700
So the first we need to do is hold up in place holder.

02:10.850 --> 02:15.010
So recall that we technically actually have two inputs which we haven't really dealt with before.

02:15.110 --> 02:20.000
We have not just these stories but we also have the questions so have the story that the encoder needs

02:20.000 --> 02:24.530
to understand then a separate question and then we have to link them together in order to provide a

02:24.530 --> 02:26.000
label yes or no.

02:26.060 --> 02:32.420
So we want to do is we're going to create place holders using input so this input function of Kerry's

02:32.450 --> 02:32.990
right here.

02:32.990 --> 02:36.710
This one input is used to instantiate a scarce tensor.

02:36.860 --> 02:44.470
So we're going to do is say a variable called input sequence is equal to input and then the formatting

02:44.480 --> 02:45.690
we're going to use here.

02:45.810 --> 02:50.240
You do shift tab here and check out that we need to pass in a shape so the shape we're gonna pass in

02:50.270 --> 02:57.290
is based on the Mac story length and next question length so we'll do here is just say Max underscore

02:57.650 --> 03:04.430
story underscore alien pops and then we're going to say comma.

03:04.470 --> 03:10.120
So the reason that we add an a comma there is because essentially since this is what's known as a place

03:10.120 --> 03:18.690
holder this is going to be able to take in the inputs of the stories with a shape of the max story length

03:18.720 --> 03:24.330
because remember going to be padding and then the batch size and the way Care's works for this batch

03:24.330 --> 03:28.870
size since we technically want to be able to edit our batch size and we don't know it yet.

03:28.980 --> 03:31.370
We're just going to leave it blank by adding in a comma.

03:31.410 --> 03:37.190
So the shape right now is a tuple with just one defined Max story length and then a comma essentially

03:37.330 --> 03:43.340
a nun there for the batch size since we technically haven't really defined it yet then we will say question

03:44.670 --> 03:51.030
input and really similarly we're going to say Max question length comma.

03:52.010 --> 03:57.920
OK so those are place holders ready to receive input later on of batches of stories and questions.

03:57.950 --> 04:00.360
Now it's time to create the input encoders.

04:00.470 --> 04:06.440
So the first thing we need to actually do is define our vocabulary size and if you remember previously

04:06.440 --> 04:09.080
we defined a vocab set.

04:09.080 --> 04:12.080
So that's basically essentially what this word index is.

04:12.080 --> 04:19.010
But if you keep going up we actually define a vocab length so in order to keep everything consistent

04:19.010 --> 04:23.660
with the notebook that we provide for you we're essentially going to create a new variable called vocab

04:23.660 --> 04:28.470
size which is the same as vocab like it's just how many words you have in your vocabulary.

04:28.490 --> 04:35.480
Remember that's this set right here plus one for padding because the zero index should be reserved due

04:35.480 --> 04:42.160
to the fact that we're using pad sequences later on over here from Charisse so scroll down here and

04:42.160 --> 04:49.650
just create one more variable called vocab size and set it equal to the length of our vocab plus one.

04:50.340 --> 04:53.670
And again just to reiterate previously we were calling this vocab length.

04:53.670 --> 04:57.990
But I want to keep the variable names the same from the vocab or from the notebook that we provided

04:57.990 --> 04:58.860
for you.

04:58.860 --> 05:04.530
So the first thing to do here is then continue on for input encoder M and then we'll create input encoder

05:04.530 --> 05:05.400
c.

05:05.580 --> 05:09.130
So this input gets embedded to a sequence of vectors.

05:09.510 --> 05:15.630
So we're gonna create a variable called input encoder M and then set it equal to sequential

05:18.530 --> 05:23.790
and then we'll say input encoder M and we're gonna add two layers to it.

05:23.810 --> 05:29.860
One is the embedding layer with an input dimension of vocab size.

05:29.930 --> 05:34.490
And if you want can technically put in vocab length here as well but we're just gonna put vocab size

05:34.490 --> 05:36.500
to keep the variable names consistent.

05:36.500 --> 05:44.340
And then from the paper we'll go ahead and use the output dimensions of sixty for and then we'll say

05:44.370 --> 05:51.900
input encoder M and we'll finally add in a dropout layer recall that a dropout layer all it does is

05:51.900 --> 05:57.330
it turns off a percentage randomly of neurons as you're training.

05:57.360 --> 06:03.780
So that means if we set dropout to zero point five that means in this layer 50 percent of the neurons

06:03.810 --> 06:08.520
are gonna be randomly turned off during the training and that helps with over fitting.

06:08.520 --> 06:10.950
So it's really up to you what value you want to choose here.

06:10.980 --> 06:13.830
You can experiment with values as well as training times.

06:13.890 --> 06:18.360
We're gonna go ahead and go off a value of zero point three but if you want you can make that a little

06:18.360 --> 06:23.370
higher and train for a little longer and see if that helps if over fitting but the way I ran this model

06:23.400 --> 06:26.170
zero point three was getting me results that were pretty darn good.

06:26.190 --> 06:27.720
So we'll go ahead use that.

06:27.840 --> 06:35.100
And so what this encoder is going to output is essentially something in the form of the samples the

06:35.100 --> 06:42.400
stories max length and then the embedding dimension.

06:42.550 --> 06:51.310
So that's input encoder M and we're gonna essentially copy and paste this for input encoder C except

06:51.310 --> 06:56.500
we'll change the variables here so input and courtesy input and courtesy input and courtesy.

06:56.740 --> 07:02.950
It's still going to be sequential except this time the output dimension isn't going to be 64 but it's

07:02.950 --> 07:08.660
going to be the max question length and then the drop out.

07:08.710 --> 07:12.760
Again you can experiment if these values of zero point three and if anything between zero and zero point

07:12.760 --> 07:18.790
five should be fine to play around with but again we'll just choose zero point three and then this will

07:18.790 --> 07:24.160
output samples story max length and then instead of the embedding dimension of the output I mentioned

07:24.160 --> 07:29.260
is this Max question length so we'll go and copy that is going to produce something that looks like

07:29.260 --> 07:29.410
that.

07:29.410 --> 07:36.850
So these are essentially what the outputs look like for these two input encoders so have an input encoder

07:36.880 --> 07:38.590
m an input encoder.

07:38.590 --> 07:45.220
See now we have one final encoder which is the question encoder again it's super similar so I'm just

07:45.220 --> 07:47.090
going to copy and paste again.

07:47.100 --> 07:56.110
What's these three layers essentially except I'll rename this to be our question encoder so have our

07:56.110 --> 08:01.930
question in Question encoder it's gonna be a sequential question encoder we'll also take in an embedding

08:01.930 --> 08:07.360
layer so I'll remove this underscore C and it's gonna take an embedding layer of the input I mentioned

08:07.420 --> 08:12.250
again it's gonna be the vocabulary size the output that I mentioned we want to match it to input encoder

08:12.250 --> 08:19.810
m just as they do in the paper so we'll say 64 and then we'll define the input length since this is

08:19.810 --> 08:24.970
specifically for questions as the max question length because remember the output I mentioned for input

08:25.000 --> 08:34.010
could see was the max question length so we're going to copy this and then say input length is equal

08:34.010 --> 08:40.170
to Max question length and then finally we'll add in this dropout layer so take that question encoder

08:40.190 --> 08:43.730
variable add that in all right.

08:44.300 --> 08:50.120
So we'll go ahead and run that and a quick note the output of what this question encoder is going to

08:50.120 --> 08:59.170
look like it's going to be samples the query max length for the question max length and then the embedding

08:59.170 --> 09:00.670
dimension.

09:00.750 --> 09:00.960
Okay.

09:01.000 --> 09:05.140
So let's synch with the output of that question and could it looks like now that we have the input encoder

09:05.140 --> 09:10.930
M input encoder C and the question encoder it's time to actually encode the sequences recall that we

09:10.930 --> 09:16.660
already have our place holders for the inputs if we scroll back up here remember we created this input

09:16.660 --> 09:22.780
sequence for an input as well as this question for an input so we want to pass in these inputs into

09:22.840 --> 09:28.030
our encoders the input encoder M input encoder C and then the question encoder just as they did in the

09:28.030 --> 09:28.840
paper.

09:29.020 --> 09:37.950
So all we need to do is say input encode Ed so make sure I spell this right in code Ed underscore M

09:38.310 --> 09:43.740
No I'm not saying encoder I'm saying this is the result of passing this in through the encoder.

09:43.740 --> 09:54.560
So essentially the form is encoded is equal to the encoder with whatever input you're passing in so

09:54.990 --> 09:56.350
I should really draw this area the other way.

09:57.780 --> 10:02.970
So we've taken our input placeholder pass it in through the encoder and we'll get our encoded result

10:03.440 --> 10:12.510
so input encoded M that's going to be equal to input encoder M and the pass in the input sequence there.

10:13.750 --> 10:18.910
And in a very similar fashion we're going to copy and paste this and we'll do the same thing for C so

10:18.910 --> 10:27.380
input encoded c is equal to the input sequence percent input encoder C and then finally we'll say question

10:28.250 --> 10:36.680
encoded is equal to the question encoder with that question placeholder pass then and now we're almost

10:36.680 --> 10:37.040
done.

10:37.250 --> 10:42.590
We just need to use a dot product to compute the match between the first input vector sequence and the

10:42.590 --> 10:45.530
query just like that in the paper to do this.

10:45.560 --> 10:51.880
I will create a variable called Match and use that dot function that we imported and then as a list

10:51.910 --> 10:56.320
you pass and the two things that you want to compute the match for or take the product up.

10:56.410 --> 11:05.290
In this case it's going to be input encoded M comma and then the actual question encoding so same question

11:06.100 --> 11:11.310
encoded and then will specify axis is two by two

11:14.110 --> 11:24.170
and then we'll call an activation function on this Max or match object by simply saying soft Max for

11:24.170 --> 11:26.290
that match object.

11:26.520 --> 11:27.230
Okay.

11:27.440 --> 11:32.060
So there we have our DOT PRODUCT compute the match between the first input vector sequence and the query

11:32.510 --> 11:37.860
and then we want to do is want to add this match matrix with the second input vector sequence.

11:38.090 --> 11:46.770
So the response is an equal to add we take that current match and then we just like that in the papers

11:46.770 --> 11:58.970
they add it to input encoded C and then the response we call that mute layer and you can check out essentially

11:58.970 --> 12:02.450
is going to permit the dimensions the input according to the given pattern.

12:02.450 --> 12:09.540
So the dimensions we're in passing is 2 by 1 and then we're going to pass in response they're essentially

12:09.540 --> 12:16.050
just converting it to have an output of samples by query max length by story max length so once we have

12:16.050 --> 12:22.200
our response we can concatenate the match matrix with the question vector sequence so we'll say our

12:22.200 --> 12:32.970
answer is equal to concatenate that response with the question encoded and to check this you should

12:32.970 --> 12:39.510
see an answer which is in the background they tensor full of tensor and you should see it.

12:39.510 --> 12:43.310
Here have a shape of question mark question mark because they don't know the batch size yet.

12:43.500 --> 12:45.400
And then six by 220.

12:45.480 --> 12:48.510
So if you're getting a result that looks like this you did everything correctly.

12:48.540 --> 12:52.360
If you get something that looks slightly different specifically differ on the shape.

12:52.360 --> 12:53.680
That's probably most important part.

12:53.850 --> 12:58.530
Then you possibly made a typo somewhere and I would highly encourage you to run through our notebook

12:58.620 --> 13:00.850
download our notebook file directly and just run that.

13:00.960 --> 13:05.210
There's lots of opportunity here to make simple typos especially with some of these variables that are

13:05.220 --> 13:08.070
look quite similar like encoder versus encoded.

13:08.190 --> 13:12.810
So if you ever get any typo or warnings along the way make sure you run our notebook in the provided

13:12.810 --> 13:13.470
environment.

13:14.430 --> 13:20.130
OK so now we have our answer tensor and then we're just going to reduce it with a recurrent neural network

13:20.160 --> 13:23.480
and we're specifically going to choose an Alice tablet for this.

13:23.580 --> 13:32.880
So you'll say answer is equal to Elysium 30 to pass in the answer and we're going to perform one more

13:32.880 --> 13:35.720
series of regularization with drop out.

13:35.820 --> 13:42.860
So answer taking a dropout layer you can choose any value here between zero and zero point five on the

13:42.900 --> 13:44.940
train a little slower so I'll choose zero point five.

13:44.970 --> 13:47.570
Try to regularize a little harder on this.

13:47.580 --> 13:51.040
Make sure to over fit.

13:51.160 --> 13:59.950
And then finally we have our dense output layer for the vocab size and we pass on our answer.

14:00.020 --> 14:04.760
So this is essentially output something that's in the form of samples by the vocab size where we should

14:04.760 --> 14:09.860
only see a marking for yes or no where everything else is just going to be a bunch of zeros just as

14:09.860 --> 14:14.120
we did we victimized the answers.

14:14.190 --> 14:14.450
All right.

14:15.350 --> 14:21.170
So what we need to do is then output a probability distribution over the vocabulary because we'll essentially

14:21.170 --> 14:25.430
see a bunch of zeros except some probability on yes and some probability I know we'll pass it in through

14:25.430 --> 14:37.780
a soft Max in order to turn it into a 0 or 1 so say answer is equal to activation soft Max passing the

14:37.780 --> 14:40.640
answer and then finally we can build the final model.

14:40.690 --> 14:46.820
So same model is equal to model it's going to take in that input sequence.

14:46.850 --> 14:51.790
Remember these are the inputs placeholders that we defined before that it's going to take in that question.

14:51.800 --> 14:57.010
And then finally it's going to take the answer and this answer is what links together all the encoders

14:57.020 --> 15:03.060
the encoder C encoder M and the question encoder and that's how we link our model to those and coatings.

15:03.080 --> 15:06.740
So we have our model here and now it's time to compile our model.

15:07.040 --> 15:15.680
We will say a model that compile the optimizer we will use optimizer is going to be Armas prop

15:18.690 --> 15:27.400
the loss we're going to use is categorical cross entropy since technically we're we're doing this across

15:27.400 --> 15:33.100
the entire vocabulary we should expect only yes as it knows across the answer but instead of doing a

15:33.460 --> 15:39.670
binary category across entropy we technically have a larger vocab size in that but the answer is we

15:39.670 --> 15:42.430
should expect to only see high probabilities on yes or no.

15:42.880 --> 15:48.460
Technically the way we're treating this it is possible for the network to output the answer as like

15:48.520 --> 15:56.370
Sandra or journey but since there are no training results with that other vocab words as the answers

15:56.380 --> 16:00.490
we shouldn't expect to see that we should really only expect see probabilities on yes or no.

16:00.490 --> 16:05.620
If you are getting results of expected probabilities of another word in the vocabulary then I would

16:05.620 --> 16:09.200
definitely look back and make sure you train the network correctly like we did.

16:09.610 --> 16:15.090
All right so we have model compile and lessening what to do is choose our metrics and the metrics reduced

16:15.080 --> 16:22.990
and shoes here is accuracy so run that and then you should be able to call a summary of your model and

16:23.020 --> 16:24.220
it's definitely complicated.

16:24.220 --> 16:28.660
Just like it wasn't a paper they should see something that looks like this with the same number of total

16:28.660 --> 16:34.290
parameters and training parameters and then all you need to do is train and fit our model.

16:34.660 --> 16:39.820
So coming up in part 4 we're going to train the model evaluate the model evaluate it on the given test

16:39.820 --> 16:43.570
set as well as write our own stories and questions and see how it can perform.

16:43.600 --> 16:47.650
So pretty exciting stuff coming up next we'll go ahead and continue on in the next lecture.

16:47.650 --> 16:48.540
I'll see you there.
