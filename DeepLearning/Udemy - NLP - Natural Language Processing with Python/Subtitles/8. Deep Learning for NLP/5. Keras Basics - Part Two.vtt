WEBVTT

00:05.240 --> 00:10.660
Now the way we do that is we first need to scale our test data or new incoming data.

00:10.680 --> 00:11.730
Now we've actually already done this.

00:11.730 --> 00:14.240
We have our skilled X test right here.

00:14.370 --> 00:19.830
But keep in mind if you had fresh data like you just went out and collected the information off a flower

00:19.830 --> 00:22.160
in the field you would have to scale that data first.

00:22.170 --> 00:28.110
Because our model is only train on the scaled versions of the sort of data and then we're going to do

00:28.260 --> 00:36.390
is if you actually take a look at model dot product just like you would for a psychic learn model the

00:36.390 --> 00:43.370
same model that predict and then pass that scaled data and then if you run this you'll notice that it

00:43.380 --> 00:47.170
actually spits out probabilities by default when you called up predict.

00:47.310 --> 00:53.430
If you want the raw classes themselves simply call predict underscore classes and it's going to predict

00:53.580 --> 00:58.650
the classes again something that's important to know here is that it doesn't predict the one encoded

00:58.680 --> 00:59.640
version of classes.

00:59.760 --> 01:05.250
It just reports back the exposition which is convenient in some senses kind of inconvenient because

01:05.940 --> 01:10.180
the original white tests we had to change it to be 100 coded.

01:10.260 --> 01:13.660
So that's a little annoying but we'll show you how to quickly fix that.

01:14.210 --> 01:14.590
OK.

01:14.760 --> 01:16.600
So we're able to not predict classes.

01:16.650 --> 01:23.610
We need to do is compare these predictions to our white test the way we're going to do that is by simply

01:23.610 --> 01:25.260
saying the following.

01:25.260 --> 01:38.650
We're going to say that our predictions is equal to model dot predicts classes on that scale x test

01:38.650 --> 01:51.340
data and then we're going to transform our Y test data by simply saying why test RMX across access is

01:51.340 --> 01:52.750
equal to one.

01:52.750 --> 01:58.190
And what that does is it reports back the actual classes because why test original.

01:58.190 --> 02:03.310
If we again take a look at it the max value is simply going to be at the expiration of the corresponding

02:03.310 --> 02:03.910
class.

02:03.910 --> 02:06.520
So that's kind of an easy fix.

02:06.520 --> 02:12.530
So now we have the predictions and our original Why test values in the exact same format.

02:12.550 --> 02:16.450
So I just need to compare these predictions to the truth values.

02:16.570 --> 02:17.580
And we already know how to do that.

02:17.640 --> 02:18.790
I sikat learn.

02:18.820 --> 02:21.890
We simply say from Eski learned that metrics import.

02:22.210 --> 02:27.090
And we're going to import the confusion matrix the classification report.

02:27.470 --> 02:32.490
And if you don't you can also import the accuracy score and then we can just play around with these.

02:32.510 --> 02:40.070
So the confusion matrix we pass why test RMX access equal to 1.

02:40.140 --> 02:46.910
So those are the true values corresponding in the same method as the predictions are going to be in.

02:47.150 --> 02:49.330
And it looks like we're doing pretty well in this confusion matrix.

02:49.340 --> 02:56.330
Let's go ahead and print out the full classification report and then just copy and paste this here

03:00.280 --> 03:01.040
from that.

03:01.480 --> 03:05.310
And we're getting a pretty good precision recall especially on this 0 class.

03:05.320 --> 03:06.880
A little rougher on this one class.

03:06.880 --> 03:10.540
And if you would actually visualize this is because there's a lot more overlap between classes 1 and

03:10.540 --> 03:11.310
2.

03:11.440 --> 03:14.220
And then finally we can print out the accuracy score.

03:14.380 --> 03:16.520
So accuracy score between these two.

03:16.720 --> 03:18.800
And we're getting around 88 percent accuracy.

03:18.850 --> 03:19.920
So not bad.

03:20.340 --> 03:20.850
OK.

03:21.100 --> 03:24.470
So we learn how to actually evaluate on unseen data.

03:24.520 --> 03:28.580
The last thing I want to do is especially for a really large network.

03:28.660 --> 03:30.580
We spent some time training it.

03:30.670 --> 03:33.710
This wasn't a big deal for this particular 150 epochs.

03:33.730 --> 03:35.290
It took just a few seconds to run.

03:35.530 --> 03:40.630
But if we're running a super large model especially for things like text generation that can take hours

03:40.630 --> 03:41.160
to run.

03:41.410 --> 03:47.530
We want to be able to save and load our model though if we do this is we simply grab our model and then

03:47.530 --> 03:48.790
call that save.

03:49.300 --> 03:51.100
And then you choose whatever you want to save it.

03:51.100 --> 03:56.130
So you say something like my first model and the extension is not H5.

03:56.200 --> 03:59.020
So this essentially saves all the weights of the network.

03:59.050 --> 04:03.420
So we're able to quickly load it up again if you want to load the model so that we.

04:03.460 --> 04:04.860
Let's imagine we shut down our computer.

04:04.870 --> 04:06.890
Next day we want to load this model that we train.

04:07.100 --> 04:17.600
All you need to do is say from cares that models import load model and we can make a new model is equal

04:17.600 --> 04:18.510
to.

04:18.680 --> 04:24.380
And then you just call the load model at the file location of where ever the H5 file is.

04:24.380 --> 04:30.770
So my first model age 5 the only thing to be really careful of is be really careful with this naming

04:30.770 --> 04:35.780
scheme because if I run this cell again multiple times after training maybe I'm just playing around

04:35.780 --> 04:36.420
of things.

04:36.500 --> 04:41.900
This will automatically overwrite any file with the exact same name that can be really dangerous especially

04:41.900 --> 04:46.310
if you have a model and your weights save that maybe took hours to run and you're just playing around

04:46.310 --> 04:48.400
and maybe do something else that took a minute to run.

04:48.500 --> 04:50.120
You will just have overwritten all that work.

04:50.120 --> 04:51.870
So be really careful this naming scheme.

04:51.920 --> 04:55.020
You don't want to overwrite a model that took forever to train.

04:55.040 --> 04:59.480
So now I have this new model essentially works the exact same way as the original simple same model.

04:59.720 --> 05:03.590
And then I can call it classes function for the generator.

05:03.590 --> 05:10.820
Anything I can passen that skill X test data run it and then get the classes predicted.

05:10.820 --> 05:11.270
OK.

05:11.570 --> 05:18.590
So that's it for evaluating model performance as well as exploring how to predict on new unseen data.

05:18.590 --> 05:20.440
All right we'll see you at the next lecture.
