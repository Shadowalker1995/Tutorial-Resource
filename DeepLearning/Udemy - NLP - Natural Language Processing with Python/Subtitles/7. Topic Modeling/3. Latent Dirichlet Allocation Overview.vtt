WEBVTT

00:05.320 --> 00:07.370
Welcome back everyone in this lecture.

00:07.390 --> 00:13.180
We're going to give an explanatory overview of how LDA or later there are only allocation for topic

00:13.180 --> 00:14.230
modeling works.

00:15.810 --> 00:21.450
Johanne there slate was a German mathematician in the 1800s who contributed widely to the field of modern

00:21.450 --> 00:22.680
mathematics.

00:22.680 --> 00:27.510
And there is a probability distribution named after him called that there is Slate distribution and

00:27.510 --> 00:34.990
this is the distribution that is used later on in LDK so late to Thursley allocation is based off this

00:34.990 --> 00:36.730
probability distribution.

00:36.940 --> 00:43.300
And in 2003 Elda was actually first published as a graphical model for topic discovery in the Journal

00:43.300 --> 00:44.920
of machine learning research.

00:44.920 --> 00:49.330
So keep in mind even though there are Schley's name is attached to this particular method for topic

00:49.330 --> 00:54.400
modeling it really just stems from the fact that it uses that there is slape probability distribution

00:54.760 --> 01:00.850
not that Thursley himself actually invented the LTA for topic modeling the actual method is relatively

01:01.000 --> 01:01.650
new.

01:01.690 --> 01:04.150
From 2003.

01:04.390 --> 01:08.490
So we're going to get a high level overview of how LDA works for topic modeling.

01:08.620 --> 01:12.900
But I would really encourage you to also take a look at the original publication paper.

01:12.920 --> 01:19.190
Now there are two main assumptions we're going to make in order to actually apply LDA for topic modeling.

01:19.190 --> 01:25.610
The first one is that documents with similar topics use similar groups of words and that's a pretty

01:25.610 --> 01:31.100
reasonable assumption because that basically saying that if you have various documents covering a similar

01:31.100 --> 01:37.070
topic like a bunch of documents covering the topic of business or economy that they should end up using

01:37.070 --> 01:42.510
similar words like money price market stocks etc..

01:42.950 --> 01:48.260
The other Sumption are going to make is that latent topic's can then be found by searching for groups

01:48.260 --> 01:53.930
of words that frequently occur together in documents across the corpus and that's going to the assumption

01:53.960 --> 01:56.690
that we're really going to dive into the details later on.

01:56.690 --> 02:00.830
So again these are the two assumptions and they're both actually quite reasonable for the way humans

02:00.830 --> 02:01.970
write documents.

02:02.270 --> 02:06.980
And we can actually think of these two assumptions mathematically the way we kind of model these assumptions

02:07.220 --> 02:08.630
is the following.

02:08.630 --> 02:14.780
We can say that documents are probability distributions over some underlying late and topics and then

02:14.780 --> 02:19.300
topics themselves are probability distributions over overworks.

02:19.310 --> 02:21.610
So let's see how each of those actually plays out.

02:22.510 --> 02:29.500
We can imagine that any particular document is going to have a probability distribution over a given

02:29.500 --> 02:31.250
amount of topics.

02:31.330 --> 02:37.990
So let's say we decide that there are five and topics across various documents than any particular document

02:38.140 --> 02:42.110
is going to have a probability of belonging to each topic.

02:42.160 --> 02:47.810
So here we can see document one has the highest probability of belonging to topic number two.

02:47.830 --> 02:52.630
So we have this discrete probability distribution across the topics for each document.

02:52.630 --> 02:56.450
Then we can look at another document such as document number 2.

02:56.530 --> 03:01.870
In this case it does have probabilities of belonging to other topics but we're going to say that it

03:01.870 --> 03:05.540
has the highest probability of belonging to Topic four.

03:05.560 --> 03:11.500
Notice here we're not saying definitively that document 1 belongs to any particular topic or document

03:11.500 --> 03:13.420
to belong to any particular topic.

03:13.420 --> 03:20.100
Instead we're modeling them as having a probability distribution over a variety of topics.

03:22.270 --> 03:27.880
And then if we look at the topics themselves those are simply going to be modeled as probability distributions

03:27.970 --> 03:29.290
over words.

03:29.290 --> 03:35.350
So for example we can define topic one as different probabilities belonging to each of these words as

03:35.350 --> 03:36.650
belonging to that topic.

03:36.940 --> 03:43.510
So we can see here that it has a low probability of the word he belong a topic one low probability of

03:43.510 --> 03:50.230
food belong a topic one etc. and then we can see that word such as cat and dog have a higher probability

03:50.500 --> 03:52.450
of belonging to topic one.

03:52.510 --> 03:57.940
And here is where we're actually going to begin as a user trying to understand what this topic is actually

03:57.940 --> 03:59.210
representative of.

03:59.230 --> 04:04.360
So if we were to get this sort of probability distribution across all the vocabulary of all the words

04:04.360 --> 04:10.390
in the corpus but we would end up doing is asking for maybe the top 10 highest probability words for

04:10.390 --> 04:16.000
topic 1 and then we would try to realize what the actual underlying topic was.

04:16.000 --> 04:21.580
So in this case we could make an educated guess that topic one happened to do with pets and we would

04:21.580 --> 04:24.160
say that topic one has to do with pets.

04:24.210 --> 04:29.710
Again the LDA or unsupervised learning technique is not going to be able to tell you that directly.

04:29.830 --> 04:35.140
It's up to the user to interpret these probability distributions as topics and we'll actually get hands

04:35.140 --> 04:38.940
on practice with that when we perform LDH ourselves of Python.

04:40.970 --> 04:49.590
So LTA represents documents as mixtures of topics that spit out words with certain probabilities and

04:49.590 --> 04:53.340
it's going to assume that documents are produced in the following fashion.

04:53.340 --> 05:00.540
It's first going to decide on the number of words and that that document will have then we choose a

05:00.540 --> 05:06.290
topic mixture that documents according to a slate distribution over a fixed set of topics.

05:06.300 --> 05:10.110
So that's where that slide distribution comes to effect.

05:10.110 --> 05:16.440
So for example we start off and say this document is 60 percent business 20 percent politics and 10

05:16.440 --> 05:17.340
percent foods.

05:17.340 --> 05:24.160
So that's her actual distribution and then what we're going to do is we're going to generate each word

05:24.160 --> 05:30.270
in the document by first picking a topic according to the multinomial distribution that we sampled previously.

05:30.310 --> 05:34.840
So we picked words 60 percent of them from the business topic 20 percent of them from politics and then

05:34.840 --> 05:40.910
10 percent from the food topic and then using the topic to generate the word itself.

05:40.910 --> 05:46.370
So again according to the topics own multinomial distribution across the words.

05:46.370 --> 05:51.800
So for example if we selected the food topic we might generate the word apple a 60 percent probability

05:52.110 --> 05:58.670
and another word home with less probability like 30 percent probability and so on.

05:58.700 --> 06:05.060
Assuming this sort of generative model for a collection of documents LDA is actually going to then try

06:05.060 --> 06:11.180
to backtrack from the documents to find the topics that are likely to have generated the collection.

06:11.180 --> 06:17.560
So again this process here that we just went over LTI is assuming that that's how you built the documents.

06:17.570 --> 06:22.160
Now obviously in the real world you're not actually building documents with this sort of frame of mind

06:22.490 --> 06:28.520
but it's a very useful construct of the way topics can be mixed throughout various documents and the

06:28.520 --> 06:31.670
way words can be mixed throughout various topics.

06:31.670 --> 06:36.880
So what we're going to do is attempt to backtrack that sort of process.

06:37.020 --> 06:41.460
So let's actually show you what else is going to do since it's assuming that that's how you built the

06:41.460 --> 06:42.600
documents.

06:42.600 --> 06:48.120
So we're can imagine we have a set of documents and the first that we have to do is actually choose

06:48.420 --> 06:53.460
some fixed number of topics to discover and you should note that very carefully that this is actually

06:53.460 --> 06:54.630
really hard.

06:54.630 --> 07:01.170
In order for LDA to work you as a user need to decide how many topics are going to be discovered.

07:01.170 --> 07:07.440
So even before you start LDA you need to have some sort of intuition over how many topics.

07:07.440 --> 07:13.560
So we choose some fixed number of topics to discover and then we're going to want to use LDA to learn

07:13.560 --> 07:18.190
the topic representation of each document and the words associated to each topic.

07:19.970 --> 07:24.920
Then we're going to go through each document and we're going to randomly assign each word in the document

07:25.220 --> 07:27.050
to one of the K topics.

07:27.050 --> 07:33.320
So keep in mind the very first pass this random assignment actually already gives you both topic representations

07:33.350 --> 07:38.960
of all the documents and word distributions of all the topics and we've assigned everything randomly

07:38.960 --> 07:44.180
at the very first pass so we're technically not done yet because these initial ran and topics won't

07:44.210 --> 07:44.980
really make sense.

07:44.990 --> 07:50.150
They're going to be really poor representations of topics since you essentially just assign every word

07:50.150 --> 07:51.130
around that topic.

07:51.140 --> 07:57.950
So now it's time to iterate over this and see if we can figure out how to fix these sort of assignments.

07:58.210 --> 08:03.190
So we're going to iterate over every word in every document to improve these topics and we're going

08:03.190 --> 08:08.300
to do it for every word in every document and for each topic.

08:08.650 --> 08:14.260
We're going to that the following we're going to calculate the proportion of words in document D that

08:14.260 --> 08:17.970
are currently assigned to topic T.

08:18.190 --> 08:23.980
Then we're also going to calculate the proportion of assignments that topic t over all documents that

08:23.980 --> 08:32.740
come from this particular word w and then we're going to reassign w a new topic where we choose topic

08:32.800 --> 08:40.980
t with probability of topic T given document the times probability of word w given topic T.

08:41.260 --> 08:48.460
So this is essentially the probability that topic t generated the word W and after repeating that previous

08:48.460 --> 08:54.730
step a large number of times we eventually reach a roughly steady state where the assignments for the

08:54.730 --> 09:02.140
topics are acceptable these words and topics don't start changing that often they become pretty steady.

09:02.140 --> 09:08.350
So at the end what we have is each document being assigned to a topic and then all we can do is we can

09:08.350 --> 09:15.540
then search for the words that have the highest probability of being assigned a topic so we end up with

09:15.540 --> 09:17.630
an output such as this will say.

09:17.640 --> 09:23.000
After running through all the documents and performing LDA you pass in one particular document and then

09:23.000 --> 09:25.580
report back LDA will report back.

09:25.590 --> 09:30.750
I think this document is assigned to topic number four and we actually don't know yet what topic number

09:30.750 --> 09:37.590
4 presents but we can ask LDA is what are the most common words in topic for what words have the highest

09:37.590 --> 09:40.190
probability of showing up a topic for.

09:40.320 --> 09:48.000
And then you may get results like cat that birds dog food home etc. and then given this list of high

09:48.000 --> 09:53.390
probability words for this particular topic it's up to the user to interpret what topic is.

09:53.550 --> 09:58.740
And for this I think a reasonable interpretation would be that these particular documents assigns a

09:58.740 --> 10:04.620
topic for probably have to do something with pets and we would say OK I think topic 4 is pets.

10:04.740 --> 10:06.290
Now is that the right answer.

10:06.300 --> 10:11.490
There's really no way of knowing because we didn't have the right answer to begin with but it's a reasonable

10:11.490 --> 10:18.820
assumption to make given the high probability of words showing up for topic for so again two important

10:18.820 --> 10:21.710
notes here before we continue and actually apply this with Python.

10:21.940 --> 10:26.920
The first important note is that the user themselves must decide on the amount of topics present in

10:26.920 --> 10:33.430
the document before even beginning this process and the second one is that the user themselves must

10:33.430 --> 10:37.350
interpret what the topics are are and what they're actually representing.

10:37.670 --> 10:43.390
OK in the next lecture we're going to explore how to actually implement LDA with Python and secular.

10:43.390 --> 10:44.100
I'll see it there.
