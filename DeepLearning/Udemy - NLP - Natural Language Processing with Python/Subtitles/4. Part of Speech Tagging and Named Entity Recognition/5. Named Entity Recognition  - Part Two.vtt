WEBVTT

00:05.360 --> 00:12.790
Welcome to part two of name recognition we just saw how we can add a single term as our own named entity.

00:12.870 --> 00:18.120
For example we saw how we could add the single term Tesla but what if we have several terms as possible

00:18.210 --> 00:23.460
named entities and this continued lecture we're going to go over how to add in multiple phrases as any

00:23.460 --> 00:24.520
are.

00:24.960 --> 00:30.120
For example if we're working with a vacuum company or their own custom text for marketing purposes we

00:30.120 --> 00:38.250
might want to add both vacuum space cleaner and vacuum cleaner as a named entity such as a product entity.

00:38.550 --> 00:43.960
Let's go ahead and jump to that you bring up and show you how you can add multiple named entities.

00:44.280 --> 00:46.100
OK here I am at the Jupiter Notebook.

00:46.140 --> 00:51.870
We're going to begin by creating a new document object and the object is going to have two strings inside

00:51.870 --> 00:55.230
of it just so we can show off multiple phrases.

00:55.230 --> 01:09.130
The first will be our company created a brand new vacuum space cleaner and then the second one another

01:09.140 --> 01:18.040
other string here all in the same function that need to separate if a comma will say this new vacuum

01:18.520 --> 01:24.010
cleaner is the best in show.

01:24.220 --> 01:28.720
So we had this new documents and noticed we have vacuum cleaner with a space between the words and vacuum

01:28.720 --> 01:30.010
cleaner of a dash.

01:30.010 --> 01:36.100
Previously if you come back up here and check our previous work we saw how to add in a single phrase

01:36.100 --> 01:39.890
or basically a single term like Tesla as a new entity.

01:40.060 --> 01:42.630
So he showed you how to do that by adding it in.

01:42.640 --> 01:48.790
Now we're going to do is we're not going to show multiple options so vacuum cleaner and vacuum cleaner

01:49.390 --> 01:55.000
and then we're going to do this is we're first going to attempt to show entities on the document just

01:55.000 --> 01:58.660
to show you that vacuum cleaner hasn't actually been added or anything.

01:58.660 --> 02:01.410
So if I run that no entities are found.

02:01.420 --> 02:08.050
So let's go ahead and add a vacuum cleaner in a vacuum cleaner as named entities to do this for multiple

02:08.050 --> 02:08.410
phrases.

02:08.410 --> 02:10.040
We're going to say it from.

02:10.870 --> 02:20.930
Matter import phrase matcher and then we will say matcher is equal to the phrase matcher and will pass

02:20.980 --> 02:28.910
in an LP vocab and the next we're going to do is create the desired list of patterns.

02:29.300 --> 02:33.950
So make a list of all the phrases you want to add in as a named entity.

02:33.950 --> 02:38.650
And for our case we want to add in vacuum cleaner so vacuum space cleaner.

02:38.780 --> 02:43.480
And we also do vacuum dash cleaner.

02:43.660 --> 02:47.890
So there's a phrase list and now we actually need to turn these into phrase patterns by passing them

02:47.890 --> 02:55.240
into the function it will say phrase patterns is equal to and we use a little bit of list comprehension

02:55.240 --> 03:05.030
here by saying a.p text for text in phrase list.

03:05.080 --> 03:11.500
After that we're going to apply the patterns to add or match or objects will say matter add and you

03:11.500 --> 03:15.460
can name whatever matcher you want so we'll just say or new product again.

03:15.490 --> 03:17.860
The string is completely up to you whatever you want to call this.

03:17.980 --> 03:21.090
Go ahead and review the vocabulary and matching lecture.

03:21.250 --> 03:21.880
When I say none.

03:21.880 --> 03:29.250
For the callback and then an Asterix and then phrase underscore patterns.

03:29.260 --> 03:35.360
This automatically adds in each of these vacuum cleaner and vacuum cleaner.

03:35.400 --> 03:42.570
So now we have our phrase patterns added as a new set of matchers called new product.

03:42.570 --> 03:52.110
Next we want to do is actually find the matches will say found matches is equal to matcher doc and we

03:52.110 --> 03:54.560
check out our found matches we found that twice.

03:54.630 --> 04:00.290
So we found that once here at the end the vacuum cleaner and here the middle this new vacuum cleaner.

04:00.300 --> 04:04.270
So there are two matches for us and then we're going to do is from here.

04:04.380 --> 04:08.560
We can actually create spans from each match in Korean names and cities from them.

04:10.140 --> 04:14.620
We will say from speccy that tokens import Spanne.

04:14.950 --> 04:16.270
That's actually the same thing we imported.

04:16.270 --> 04:22.270
We were adding just a single term and then it's up to you to decide what actual names and dates you

04:22.270 --> 04:22.940
want.

04:22.990 --> 04:27.170
You can check out our names and it's the recognition notebook for all the various tags.

04:27.430 --> 04:35.000
In this case we're going to say these vacuum cleaners are a product sort of come back here and say Prod.

04:35.630 --> 04:40.680
is equal to Doc dot vocab dot strings.

04:40.970 --> 04:46.360
And as a unicode string what you're going to do is passen whatever the string here for a type is.

04:46.370 --> 04:54.550
And in our case it's all caps product so recopy this one person in here and then we're going to use

04:54.550 --> 04:56.500
a little bit of miscomprehension here.

04:56.500 --> 05:01.330
So recall that inside a found matches there's tuples with three items in it.

05:01.330 --> 05:06.550
We're really only concerned with these two items the start and the end and we're going to use span to

05:06.550 --> 05:10.080
actually define the start the span and the end of the span.

05:10.180 --> 05:15.160
So I to have something that looks like this span going to pass in the document.

05:15.190 --> 05:20.110
That is the original document appear where our company created brand new vacuum cleaner this new vacuum

05:20.110 --> 05:21.390
cleaner is best in show.

05:21.730 --> 05:27.000
So that's the documents and then we're going to actually grab for each match.

05:27.250 --> 05:38.470
Index one start and then index to its end and we're going to say that its label should be Prod. which

05:38.470 --> 05:42.380
was defined here using doc that vocab.

05:42.380 --> 05:46.840
And we're going to be creating these spans for every single match inside of found matches so we can

05:46.840 --> 05:56.470
use some LIT's comprehension to say inside of this list for match in found matches and we're going to

05:56.470 --> 06:00.210
set this equal to our new entities.

06:00.210 --> 06:05.420
Again we're just creating these span objects using the original documents and all the found matches

06:05.430 --> 06:10.890
the start and the stop and then manually labeling them as a product.

06:10.890 --> 06:18.560
So there we have our new entities and then we take the doc and say those are the original entities that

06:18.570 --> 06:28.460
are documents we're going to set it equal to the original entities Plus our new entities.

06:28.510 --> 06:29.490
And you could also use a pen.

06:29.500 --> 06:35.070
But this works the same way in Python essentially all we're doing is remember Doc ants originally it

06:35.070 --> 06:36.500
has no entities.

06:36.520 --> 06:43.680
Now we're taking this list of new entities that we find and then adding it into the original which means

06:43.680 --> 06:51.060
now if I say show entities on the document it returns back both vacuum space cleaner and vacuum cleaner

06:51.540 --> 06:52.950
as products.

06:52.950 --> 06:59.730
So this is now how you can manually add in your own named entities if you have a list of entities you

06:59.730 --> 07:02.070
want to pass in.

07:02.080 --> 07:08.550
Now previously we saw how Spacey had built in tools for counting the number of parts of speech.

07:08.680 --> 07:14.860
It actually doesn't have a built in count by method for counting the number of named entities but we

07:14.860 --> 07:17.920
can easily do this with a little bit of list comprehension.

07:17.920 --> 07:21.190
And in fact we can't even filter based off the label.

07:21.190 --> 07:25.510
So what we can do here is let's imagine we have in other documents

07:29.730 --> 07:35.130
and we wanted to figure out how many times was a money entity mentioned.

07:35.510 --> 07:38.160
So say originally I paid

07:41.330 --> 07:47.890
will say twenty nine ninety five for this car.

07:47.890 --> 08:00.900
Or let's say car toy if I preachy for your car and then we'll say but now it is marked down by $10.

08:01.050 --> 08:05.670
OK so we have this documents and let's say this documents really long and you want to figure out how

08:05.670 --> 08:10.310
many times was money mentioned here or any type of named entity you have.

08:10.470 --> 08:15.930
So you say how many times were people mentioned or was a corporation or a nationality mentioned et cetera.

08:15.930 --> 08:18.150
Right now we're just looking for this money tag.

08:18.150 --> 08:20.220
How many of those do we actually have.

08:20.220 --> 08:22.920
All we need to do is the following.

08:22.920 --> 08:32.120
We can simply create a list comprehension saying give me the entity for every entity in dock in TS.

08:32.430 --> 08:37.440
If you just check this list right here that's going to give you every single entity but you only want

08:37.440 --> 08:38.590
a specific entity.

08:38.640 --> 08:46.040
So you'll say if Antz label underscore is equal to and then whatever else you're interested in.

08:46.080 --> 08:47.610
In our case it's money.

08:47.670 --> 08:52.590
So if you run that that gives the entities and if you want to check how many of them you can just check

08:52.590 --> 08:54.490
the length of that list

08:58.390 --> 09:01.920
that is it for this series of lectures on named entities.

09:01.990 --> 09:08.440
I hope you can tell just how powerful Spacey is even on its own at recognizing named entities and the

09:08.440 --> 09:13.480
flexibility it gives you to add not just single terms but multiple named entities for your own custom

09:13.480 --> 09:14.970
text data sets.

09:14.980 --> 09:19.760
We'll see you at the next lecture where we talk in more depth about visualizing named entity recognition.
