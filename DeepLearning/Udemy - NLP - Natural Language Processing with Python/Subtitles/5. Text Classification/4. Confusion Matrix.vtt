WEBVTT

00:05.350 --> 00:06.260
Welcome back everyone.

00:06.280 --> 00:09.480
This lecture on the confusion matrix.

00:09.540 --> 00:14.560
We mentioned the way to view various metrics of classification is called the confusion matrix.

00:14.730 --> 00:21.280
Let's explore the basics of the confusion matrix to help us understand precision and recall better in

00:21.280 --> 00:23.980
the classification problem during testing phase.

00:24.040 --> 00:26.020
You're going to have two main categories.

00:26.110 --> 00:32.980
The true condition and the predictive condition for example the true condition of a text message could

00:32.980 --> 00:34.570
be that it is spam.

00:34.690 --> 00:39.160
The predicted condition is what you're machine learning model predicted such as predicting that that

00:39.160 --> 00:41.170
test message was spam.

00:41.170 --> 00:46.310
Keep in mind it could have also pricked it that it incorrectly as him.

00:46.340 --> 00:51.800
This means if you have two possible classes you should have four separate groups at the end of testing.

00:51.890 --> 00:54.690
You have correctly classified the class 1.

00:54.740 --> 01:00.740
So that means you had a message that was him and you positively identified it as him.

01:00.740 --> 01:03.080
There's also correctly classified the class too.

01:03.380 --> 01:08.580
So something was truly spam and then you correctly identified it as spam.

01:08.600 --> 01:15.710
Then there's the other two options incorrectly classifying something to class 1 or incorrectly classifying

01:15.710 --> 01:20.820
something into class to a false ham or false spam.

01:20.850 --> 01:25.240
So if we were to map these out in a little grid we'd have something that looks like this.

01:25.260 --> 01:28.470
And this is the confusion matrix and is the confusion matrix.

01:28.470 --> 01:32.970
If you look it up on Wikipedia which is actually a really helpful article on this it would map out something

01:32.970 --> 01:33.980
that looks like this.

01:35.150 --> 01:40.100
So if we were to actually look at it a little more simplified for our particular example going back

01:40.100 --> 01:41.550
to those text messages.

01:41.690 --> 01:46.630
Again we have the real condition and the predicted condition so we can see over on the left hand side

01:46.630 --> 01:48.680
if we're going to have two real conditions.

01:48.680 --> 01:52.310
The real condition is either him or real condition spam.

01:52.520 --> 01:58.690
And then along the columns we have our predicted condition predicting him or predicting spam.

01:58.720 --> 02:04.820
You'll notice that if the real condition is him and we predicted him then we have a true positive.

02:04.840 --> 02:11.010
We correctly predicted that this was positively him along the predicted condition as well.

02:11.010 --> 02:12.940
We have a false negative.

02:12.990 --> 02:17.370
That means that the real condition was him but our machine learning model incorrectly predicted it to

02:17.370 --> 02:18.260
be spam.

02:18.270 --> 02:20.760
That's a false negative here.

02:20.800 --> 02:25.060
Relabeling him as positive and spam as negative.

02:25.110 --> 02:28.470
We also see that we have real conditions spam and then predicted him.

02:28.470 --> 02:33.420
That's known as a false positive falsely identifying something to the positive class which in this case

02:33.420 --> 02:34.450
is him.

02:34.470 --> 02:36.960
We also finally true negative correctly.

02:36.970 --> 02:42.260
And the feeling something to the negative class predicting spam free spam text message.

02:42.270 --> 02:47.280
Now if we come back to that other confusion matrix that we saw earlier we can expand on this to have

02:47.280 --> 02:53.430
quite a wide variety of different metrics we can calculate things like true positive rate false positive

02:53.430 --> 02:57.400
rate positive likelihood ratio false emission rate etc..

02:57.660 --> 02:59.790
But really we're just concerned for a few of these.

02:59.880 --> 03:03.450
We're concerned with recall accuracy and precision.

03:03.750 --> 03:09.280
And here I can see a bunch of formulas for actually calculating those now the main point to remember

03:09.280 --> 03:14.170
is the confusion matrix and the various calculated metrics is that they are all fundamentally ways of

03:14.170 --> 03:19.660
comparing the predicted values versus the true values and what constitutes good metrics will really

03:19.660 --> 03:21.970
depend on the specific situation.

03:22.210 --> 03:25.610
In some situations 99 percent accuracy is fantastic.

03:25.690 --> 03:26.620
In other situations.

03:26.640 --> 03:31.420
Ninety nine percent accuracy may actually not be good enough for whatever you're are trying to predict

03:31.750 --> 03:35.900
because maybe it comes at the cost of a really poor precision and poor recall.

03:36.040 --> 03:41.400
So we can't just say that there's certain good values for particular metrics.

03:41.410 --> 03:46.990
Obviously if you get 100 percent across precision accuracy and recall if you get across a hundred percent

03:47.050 --> 03:49.410
on all three of those then you have a really good model.

03:49.420 --> 03:55.070
But in the real world you're probably not going to get 100 percent of all those.

03:55.090 --> 03:58.840
So let's go ahead and use confusion matrix to evaluate our model.

03:58.840 --> 04:01.600
Let's imagine now we're testing for a disease.

04:01.630 --> 04:07.270
So in this example we're going to test for the presence of a disease and we have the actual patients

04:07.270 --> 04:07.850
come in.

04:07.870 --> 04:09.810
Remember this is supervised learning.

04:09.820 --> 04:15.250
So before we actually run them through the testing program we actually already know the true conditions

04:15.280 --> 04:19.980
of these patients whether or not they had disease or don't have these.

04:20.020 --> 04:23.640
So you can imagine that we're testing a new diagnostic tool.

04:23.660 --> 04:30.050
So in this case for example test for presence of disease we'll say no is equal to a negative test or

04:30.050 --> 04:30.770
false.

04:30.770 --> 04:35.000
Often you just say that zero or yes is a positive test which is true.

04:35.030 --> 04:36.580
And again you say that's one.

04:36.650 --> 04:43.180
So in this particular example the total number of patients we have for this new diagnostic test is 165.

04:43.190 --> 04:49.820
So we say end is equal to 165 and then we have the results as follows of the condition that people did

04:49.820 --> 04:51.400
not have the condition.

04:51.410 --> 04:55.390
Maybe we're testing for something like a cancer in this particular example.

04:55.430 --> 05:00.240
There's 50 people that didn't have cancer that we correctly predicted they don't have cancer.

05:00.230 --> 05:07.400
So we say predicted no actual no 50 then we can also see that we actually predicted 10 people to have

05:07.430 --> 05:08.210
disease.

05:08.450 --> 05:11.050
And these people actually did not have disease.

05:11.060 --> 05:17.810
So those 10 were incorrect that we also see that we have actually yes and predicted no as 5 and then

05:17.900 --> 05:20.360
actually yes or predicted Yes as 100

05:23.290 --> 05:29.280
so some basic terminology here are true positives true negatives false positives and false negatives.

05:29.340 --> 05:34.470
So you can see here on the great how that actually lines up and keep in mind you can kind of flip this

05:34.470 --> 05:41.130
the order no versus Yes on either the columns or the rows in order to flip the quadrants of negatives

05:41.130 --> 05:46.290
versus positives in the original confusion matrix we showed it in this lecture that was actually flipped.

05:46.290 --> 05:49.400
So keep in mind you may see the confusion matrix both ways.

05:49.500 --> 05:52.740
But other than that the information presented is still the same.

05:52.800 --> 05:55.190
It's just the quadrants are slightly rotated.

05:57.480 --> 06:01.880
So if we're trying to answer a question like What is the accuracy of this test.

06:01.920 --> 06:07.290
We ask ourselves how often is it correct and for accuracy it's just equal to true positives.

06:07.290 --> 06:13.290
Plus true negatives divided by the total essentially asking the question How many did I classify correctly

06:13.560 --> 06:15.060
over all my examples.

06:15.120 --> 06:21.270
And in this case we get 150 divided by the total number which was 165 and that means that our test was

06:21.270 --> 06:22.960
91 percent accurate.

06:23.190 --> 06:25.020
Now is 91 percent accurate.

06:25.200 --> 06:26.130
Good enough.

06:26.130 --> 06:28.000
That really depends on the situation.

06:28.200 --> 06:33.090
If you're dealing with something that's as high stakes as something like cancer 91 percent accuracy

06:33.540 --> 06:34.650
may not be good enough.

06:34.830 --> 06:41.010
And you also have to take into the context of precision and recall notice that a really important statistic

06:41.010 --> 06:48.120
here is the false negative the false negative means that you knew this person when you're going through

06:48.120 --> 06:49.960
the test actually had the disease.

06:50.100 --> 06:53.530
But the machine learning model predicted them as not having the disease.

06:53.760 --> 06:59.940
That's an extremely dangerous situation to be in when the stakes are very high like a cancer diagnostic

07:00.240 --> 07:05.150
because that means someone that actually has a disease you're telling them they do not have it.

07:05.460 --> 07:11.800
So you have to keep in context the entire idea of what you're machine learning model is trying to achieve.

07:12.000 --> 07:18.990
So there's always going to be a bit of a tradeoff between false negatives and false positives and ideally

07:19.080 --> 07:23.790
for something like this where we're dealing with a really high stakes situation and we want to make

07:23.790 --> 07:26.340
sure we minimize the false negatives.

07:26.340 --> 07:29.800
It doesn't matter too much in kind of a diagnostic sense.

07:29.910 --> 07:35.010
If we have a larger amount of false positives in order to lower our false negatives because we would

07:35.010 --> 07:40.110
rather set up a situation where we tell a patient that they have a disease when they actually don't

07:40.110 --> 07:44.650
have it and then conclude that they are in line now for further diagnostic tests.

07:44.820 --> 07:47.720
Again it depends on the context of what the next steps are.

07:47.760 --> 07:52.080
What we'd really like to avoid in this situation when it comes to disease is telling someone they're

07:52.100 --> 07:54.750
clear of the disease when they actually have it.

07:54.750 --> 08:00.090
So again there's no right or wrong answer as far as what your false positive rate or false negative

08:00.090 --> 08:01.230
rate should be.

08:01.230 --> 08:06.750
It really depends on the context of the situation and how important each of these are in the overall

08:06.750 --> 08:07.350
study.

08:09.530 --> 08:14.150
Now there's other things you can calculate such as the misclassification Ree or Airey.

08:14.300 --> 08:17.650
That's another one that's essentially the reverse of accuracy.

08:17.660 --> 08:20.660
It's just asking overall how often am I wrong.

08:20.660 --> 08:25.370
So that's false positives plus false negatives divided by a total or 100 minus accuracy.

08:25.370 --> 08:33.810
So in this case where 9 percent error rate in other common thing to keep in mind is that in statistics

08:34.170 --> 08:39.060
false positives and false negatives are often referred to as type 1 errors and type 2 errors.

08:39.120 --> 08:44.100
And here you can see kind of a funny example in order to keep in mind the differences between the two.

08:44.400 --> 08:45.440
A false positive.

08:45.660 --> 08:47.370
Here we're telling the man that they're pregnant.

08:47.400 --> 08:52.910
Clearly this person cannot be pregnant or the false negative in which case this woman is clearly pregnant.

08:52.910 --> 08:54.740
What we're telling them they're not pregnant.

08:54.870 --> 08:56.230
So keep mine in statistics.

08:56.250 --> 09:01.320
You may see type 1 error and type 2 error instead of the terms false positives and false negatives.

09:03.380 --> 09:06.550
If you're still confused the confusion matrix don't worry too much about it.

09:06.590 --> 09:09.080
I would encourage you to check out the Wikipedia page for it.

09:09.080 --> 09:13.310
It has a really good diagram that we saw during this lecture with all the formulas for all the metrics

09:13.790 --> 09:14.610
throughout the training.

09:14.690 --> 09:19.460
What we're going to be doing is just printing out metrics for example just print the accuracy or print

09:19.460 --> 09:24.350
out a confusion matrix or print out what's known as a classification report which reports back precision

09:24.470 --> 09:26.500
recall an F1 score.

09:26.500 --> 09:29.800
Again it takes time to really get an understanding of these metrics.

09:29.990 --> 09:32.080
And more importantly an intuition behind them.

09:32.360 --> 09:38.810
Check out the resource links for this lecture in order to help your understanding of things like precision

09:38.990 --> 09:40.970
recall and accuracy.

09:40.970 --> 09:41.660
All right.

09:41.660 --> 09:47.330
Coming up next we're going to discuss a primer into using Python's sikat learn machine learning library

09:47.640 --> 09:48.770
will see at the next lecture.
